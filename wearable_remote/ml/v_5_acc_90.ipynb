{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#### Импорт необходимых библиотек"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-13T01:32:46.912253Z",
     "start_time": "2024-10-13T01:32:46.867012300Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import speech_recognition as sr\n",
    "import soundfile as sf\n",
    "import os\n",
    "\n",
    "# 1. Функция для загрузки шумовых образцов\n",
    "def load_noise_samples(noise_dir):\n",
    "    \"\"\"Загрузить и объединить шумовые образцы в один аудиофайл\"\"\"\n",
    "    noise_files = [os.path.join(noise_dir, f) for f in os.listdir(noise_dir) if f.endswith('.wav')]\n",
    "    noises = []\n",
    "    for noise_file in noise_files:\n",
    "        noise, sr = librosa.load(noise_file, sr=16000)\n",
    "        noises.append(noise)\n",
    "    combined_noise = np.concatenate(noises)\n",
    "    return combined_noise, sr\n",
    "\n",
    "# 2. Функция для удаления шума\n",
    "def reduce_noise(audio_file, noise_dir, output_file, noise_reduction_factor=1):\n",
    "    \"\"\"\n",
    "    Удалить шум из голосового сообщения.\n",
    "    \"\"\"\n",
    "    # Загрузить аудиофайл с голосом\n",
    "    voice, sr = librosa.load(audio_file, sr=16000)\n",
    "\n",
    "    # Загрузить шумы\n",
    "    noise, sr_noise = load_noise_samples(noise_dir)\n",
    "\n",
    "    if sr != sr_noise:\n",
    "        raise ValueError(\"Частоты дискретизации аудиофайла и шума не совпадают\")\n",
    "\n",
    "    # Убедиться, что длина шума соответствует длине аудио (или короче)\n",
    "    noise = noise[:len(voice)]\n",
    "\n",
    "    # Преобразование аудио и шума в STFT (Short-Time Fourier Transform)\n",
    "    voice_stft = librosa.stft(voice)\n",
    "    noise_stft = librosa.stft(noise)\n",
    "\n",
    "    # Усреднить шумы по времени\n",
    "    noise_mean = np.mean(np.abs(noise_stft), axis=1)\n",
    "\n",
    "    # Вычесть шум из голоса\n",
    "    voice_clean_stft = voice_stft - noise_reduction_factor * noise_mean[:, np.newaxis]\n",
    "\n",
    "    # Преобразовать обратно в аудиосигнал\n",
    "    voice_clean = librosa.istft(voice_clean_stft)\n",
    "\n",
    "    # Сохранить очищенный аудиофайл\n",
    "    sf.write(output_file, voice_clean, sr)\n",
    "\n",
    "    print(f\"Шум успешно удален и файл сохранен в {output_file}\")\n",
    "    return output_file\n",
    "\n",
    "# 3. Функция для преобразования речи в текст\n",
    "def speech_to_text(audio_path):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_path) as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "        try:\n",
    "            text = recognizer.recognize_google(audio_data, language='ru-RU')\n",
    "            return text\n",
    "        except sr.UnknownValueError:\n",
    "            return \"Не удалось распознать речь\"\n",
    "        except sr.RequestError as e:\n",
    "            return f\"Ошибка сервиса: {e}\"\n",
    "\n",
    "# 4. Функция для создания модели классификации текста\n",
    "def build_text_classifier(num_classes):\n",
    "    model = keras.Sequential([\n",
    "        layers.Embedding(input_dim=1000, output_dim=64),\n",
    "        layers.GlobalAveragePooling1D(),\n",
    "        layers.Dense(16, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')  # Предположим, num_classes категорий\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 5. Основная функция обработки аудиофайла\n",
    "def process_audio_file(audio_path, noise_dir, categories):\n",
    "    # Удаление шума\n",
    "    cleaned_audio = reduce_noise(audio_path, noise_dir, 'cleaned_voice_message.wav')\n",
    "\n",
    "    # Преобразование речи в текст\n",
    "    text = speech_to_text(cleaned_audio)\n",
    "    print(\"Распознанный текст:\", text)\n",
    "\n",
    "    # Преобразование текста в массив для классификации\n",
    "    text_input = np.array([text])  # Пример преобразования текста в массив\n",
    "\n",
    "    # Создание и обучение модели (или загрузка предварительно обученной модели)\n",
    "    model = build_text_classifier(num_classes=len(categories))\n",
    "\n",
    "    # Здесь должен быть код для загрузки и подготовки данных для обучения\n",
    "    # model.fit(training_data, training_labels, epochs=10)  # Пример обучения\n",
    "\n",
    "    # Предсказание категории\n",
    "    prediction = model.predict(text_input)\n",
    "    predicted_category = categories[np.argmax(prediction)]\n",
    "    print(\"Предсказанная категория:\", predicted_category)\n",
    "\n",
    "    return model  # Вернуть модель для сохранения\n",
    "\n",
    "# 6. Сохранение модели в формате TFLite\n",
    "def save_model_to_tflite(model, filename):\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    tflite_model = converter.convert()\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "\n",
    "# Использование\n",
    "audio_file_path = \"path/to/your/audio/file.wav\"\n",
    "noise_directory = \"path/to/your/noise/files\"\n",
    "categories = [\n",
    "    \"отказ\",\n",
    "\"отмена\",\n",
    "\"подтверждение\",\n",
    "\"начать осаживание\",\n",
    "\"осадить на (количество) вагон\",\n",
    "\"продолжаем осаживание\",\n",
    "\"зарядка тормозной магистрали\",\n",
    "\"вышел из межвагонного пространства\",\n",
    "\"продолжаем роспуск\",\n",
    "\"растянуть автосцепки\",\n",
    "\"протянуть на (количество) вагон\",\n",
    "\"отцепка\",\n",
    "\"назад на башмак\",\n",
    "\"захожу в межвагонное пространство\",\n",
    "\"остановка\",\n",
    "\"вперед на башмак\",\n",
    "\"сжать автосцепки\",\n",
    "\"назад с башмака\",\n",
    "\"тише\",\n",
    "\"вперед с башмака\",\n",
    "\"прекратить зарядку тормозной магистрали\",\n",
    "\"тормозить\",\n",
    "\"отпустить\",\n",
    "]\n",
    "\n",
    "\n",
    "# Обработка аудиофайла и получение модели\n",
    "model = process_audio_file(audio_file_path, noise_directory, categories)\n",
    "\n",
    "# Сохранение модели в TFLite формат\n",
    "save_model_to_tflite(model, 'text_classifier_model.tflite')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
