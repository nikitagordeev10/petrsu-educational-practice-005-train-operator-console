{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#### Импорт необходимых библиотек"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import speech_recognition as sr\n",
    "from transformers import Wav2Vec2Tokenizer, Wav2Vec2ForCTC\n",
    "import torch\n",
    "import logging\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Создание констант"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Константы\n",
    "DATA_DIR = '../data/train/'\n",
    "DATA_DIR_FILES = [\n",
    "    'hr_bot_clear',\n",
    "    'hr_bot_noise',\n",
    "    'hr_bot_synt'\n",
    "]\n",
    "ANNOTATION_DIR = '../data/train/annotation/'\n",
    "ANNOTATION_FILES = [\n",
    "    'hr_bot_clear.json',\n",
    "    'hr_bot_noise.json',\n",
    "    'hr_bot_synt.json'\n",
    "]\n",
    "\n",
    "VAL_DIR = '../data/val/luga/'  # Путь к валидационным данным\n",
    "ANNOTATION_VAL_FILE = os.path.join(VAL_DIR, 'luga.json')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Подготовка данных\n",
    "Загружаем аудиофайлы и аннотации, которые содержат информацию о командах (текст команды, класс команды, атрибуты). Данные могут быть разделены на чистые (без шума) и зашумленные."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Преобразование MP3 в WAV\n",
    "def convert_mp3_to_wav(mp3_filepath):\n",
    "    try:\n",
    "        wav_filepath = mp3_filepath.replace('.mp3', '.wav')\n",
    "        audio = AudioSegment.from_mp3(mp3_filepath)\n",
    "        audio.export(wav_filepath, format='wav')\n",
    "        return wav_filepath\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при конвертации {mp3_filepath} в WAV: {e}\")\n",
    "        return None\n",
    "\n",
    "# Функция загрузки аннотаций\n",
    "def load_annotations(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# Загрузка датасета с аннотациями\n",
    "def load_dataset(data_dir, annotation_files):\n",
    "    dataset = []\n",
    "    # Перебираем файлы аннотаций\n",
    "    for annotation_file in annotation_files:\n",
    "        annotations = load_annotations(os.path.join(ANNOTATION_DIR, annotation_file))\n",
    "\n",
    "        # Получаем соответствующую директорию на основе названия файла аннотации\n",
    "        sub_dir = annotation_file.replace('.json', '')\n",
    "        print(f\"Loading from subdirectory: {sub_dir}\")\n",
    "\n",
    "        for item in annotations:\n",
    "            if all(k in item for k in ['audio_filepath', 'text', 'label', 'attribute']):\n",
    "                # Используем os.path.join для правильного формирования пути\n",
    "                audio_path = os.path.join(data_dir, sub_dir, item['audio_filepath'])\n",
    "                print(f\"Checking audio file path: {audio_path}\")\n",
    "\n",
    "                if os.path.exists(audio_path):\n",
    "                    # Преобразуем MP3 в WAV, если файл в формате MP3\n",
    "                    if audio_path.endswith('.mp3'):\n",
    "                        audio_path = convert_mp3_to_wav(audio_path)\n",
    "\n",
    "                    if audio_path:  # Убедимся, что преобразование прошло успешно\n",
    "                        dataset.append({\n",
    "                            'audio_filepath': audio_path,\n",
    "                            'text': item['text'],\n",
    "                            'label': item['label'],\n",
    "                            'attribute': item['attribute']\n",
    "                        })\n",
    "                else:\n",
    "                    print(f\"Audio file does not exist: {audio_path}\")\n",
    "            else:\n",
    "                print(f\"Missing keys in item: {item}\")\n",
    "    return dataset\n",
    "\n",
    "# Загрузка данных\n",
    "dataset = load_dataset(DATA_DIR, ANNOTATION_FILES)\n",
    "df = pd.DataFrame(dataset)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Извлечение признаков из аудиофайлов\n",
    "Для того чтобы классифицировать команды, извлекаем признаки из аудиофайлов. Одним из эффективных методов является использование MFCC (Mel-Frequency Cepstral Coefficients)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Функция извлечения MFCC признаков\n",
    "def extract_features(audio_filepath):\n",
    "    try:\n",
    "        # Загрузка аудиофайла\n",
    "        signal, sr = librosa.load(audio_filepath, sr=None)\n",
    "        # Извлечение MFCC\n",
    "        mfccs = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=13)\n",
    "        return np.mean(mfccs.T, axis=0)\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при обработке {audio_filepath}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Извлечение признаков\n",
    "df['features'] = df['audio_filepath'].apply(extract_features)\n",
    "df = df.dropna()  # Удаляем строки с ошибками\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Разделение данных на обучающую и тестовую выборки\n",
    "После извлечения признаков, разделяем данные на тренировочную и тестовую выборки для обучения модели."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = np.array(df['features'].tolist())\n",
    "y = np.array(df['label'])\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Построение нейронной сети\n",
    "Создаем нейронную сеть для классификации команд. Модель будет иметь несколько скрытых слоев и выходной слой с количеством нейронов, равным числу классов команд."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Определение модели\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Input(shape=(13,)),  # Входной слой (13 признаков из MFCC)\n",
    "    layers.Dense(64, activation='relu'),  # Первый скрытый слой\n",
    "    layers.Dense(64, activation='relu'),  # Второй скрытый слой\n",
    "    layers.Dense(23, activation='softmax')  # Выходной слой (23 класса команд)\n",
    "])\n",
    "\n",
    "# Компиляция модели\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Обучение модели извлечения текста из аудиофайлов\n",
    "Обучаем модель на подготовленных данных."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Обучение модели\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Оценка модели\n",
    "Оцениваем качество модели на тестовой выборке для проверки точности распознавания команд."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Оценка модели на тестовой выборке\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Сохранение модели\n",
    "После обучения сохраняем модель для дальнейшего использования."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Сохранение модели\n",
    "model.save('train_command_model.h5')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Распознавание речи (speech-to-text)\n",
    "Для преобразования аудио в текст можно использовать библиотеку speech_recognition или предварительно обученные модели, такие как Wav2Vec2."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Функция для распознавания речи\n",
    "def transcribe_audio(audio_filepath):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_filepath) as source:\n",
    "        audio = recognizer.record(source)\n",
    "        try:\n",
    "            text = recognizer.recognize_google(audio)  # Можно использовать оффлайн-модель Wav2Vec2\n",
    "            print(f\"Recognized Text: {text}\")\n",
    "            return text\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Speech Recognition could not understand audio\")\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Error in Speech Recognition service: {e}\")\n",
    "    return None\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Классификация текста команды"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Классы команд\n",
    "label = {\n",
    "    0: \"отказ\",\n",
    "    1: \"отмена\",\n",
    "    2: \"подтверждение\",\n",
    "    3: \"начать осаживание\",\n",
    "    4: \"осадить на (количество) вагон\",\n",
    "    5: \"продолжаем осаживание\",\n",
    "    6: \"зарядка тормозной магистрали\",\n",
    "    7: \"вышел из межвагонного пространства\",\n",
    "    8: \"продолжаем роспуск\",\n",
    "    9: \"растянуть автосцепки\",\n",
    "    10: \"протянуть на (количество) вагон\",\n",
    "    11: \"отцепка\",\n",
    "    12: \"назад на башмак\",\n",
    "    13: \"захожу в межвагонное,пространство\",\n",
    "    14: \"остановка\",\n",
    "    15: \"вперед на башмак\",\n",
    "    16: \"сжать автосцепки\",\n",
    "    17: \"назад с башмака\",\n",
    "    18: \"тише\",\n",
    "    19: \"вперед с башмака\",\n",
    "    20: \"прекратить зарядку тормозной магистрали\",\n",
    "    21: \"тормозить\",\n",
    "    22: \"отпустить\",\n",
    "}\n",
    "\n",
    "# Функция для классификации команды\n",
    "def classify_command(text):\n",
    "    for command in _label.values():\n",
    "        if command in text:\n",
    "            return command\n",
    "    return \"Unknown Command\"\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Проверка точности на реальных данных\n",
    "Проверяем работу системы на новых аудиофайлах и оцениваем точность распознавания и классификации."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate_commands():\n",
    "    annotations = load_annotations(ANNOTATION_FILE)\n",
    "    correct_predictions = 0\n",
    "    total_predictions = len(annotations)\n",
    "\n",
    "    # Словарь для хранения статистики\n",
    "    statistics = {\n",
    "        'correct': {},\n",
    "        'total': {},\n",
    "        'accuracy': {}\n",
    "    }\n",
    "\n",
    "    for item in annotations:\n",
    "        audio_filepath = item['audio_filepath']\n",
    "        label = item['label']\n",
    "\n",
    "        audio_path = os.path.join(VAL_DIR, audio_filepath)\n",
    "        if os.path.exists(audio_path):\n",
    "            prediction = predict_command(audio_path)\n",
    "            print(f'Predicted: {prediction}, Actual: {label} for {audio_path}')\n",
    "\n",
    "            if prediction == label:\n",
    "                correct_predictions += 1\n",
    "\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    # Сохраняем точность в статистике\n",
    "    statistics['accuracy'] = accuracy\n",
    "\n",
    "    # Выводим статистику\n",
    "    print(f'\\nTotal Predictions: {total_predictions}')\n",
    "    print(f'Correct Predictions: {correct_predictions}')\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print('Detailed statistics per label:')\n",
    "    for label in statistics['total']:\n",
    "        total = statistics['total'][label]\n",
    "        correct = statistics['correct'].get(label, 0)\n",
    "        print(f'Label: {label}, Total: {total}, Correct: {correct}, Accuracy: {correct / total:.2f}' if total > 0 else f'Label: {label}, Total: {total}, Correct: {correct}')\n",
    "\n",
    "\n",
    "evaluate_commands()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
