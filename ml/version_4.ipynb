{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-10-12T13:59:10.279221700Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import wave\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from pydub import AudioSegment\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from vosk import Model, KaldiRecognizer\n",
    "import jiwer\n",
    "\n",
    "# Константы\n",
    "DATA_DIR = '../data/train/'\n",
    "DATA_DIR_FILES = [\n",
    "    'hr_bot_clear',\n",
    "    'hr_bot_noise',\n",
    "    'hr_bot_synt'\n",
    "]\n",
    "ANNOTATION_DIR = '../data/train/annotation/'\n",
    "ANNOTATION_FILES = [\n",
    "    'hr_bot_clear.json',\n",
    "    'hr_bot_noise.json',\n",
    "    'hr_bot_synt.json'\n",
    "]\n",
    "\n",
    "VAL_DIR = '../data/val/luga/'  # Путь к валидационным данным\n",
    "ANNOTATION_VAL_FILE = os.path.join(VAL_DIR, 'luga.json')\n",
    "\n",
    "# Настройка Vosk модели для распознавания речи\n",
    "MODEL_PATH = \"../model/vosk_model\"  # Путь к скачанной модели Vosk\n",
    "vosk_model = Model(MODEL_PATH)\n",
    "\n",
    "# Нейронная сеть для классификации текста\n",
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Датасет для классификации текста\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.labels[idx]\n",
    "\n",
    "# Преобразование MP3 в WAV\n",
    "def convert_mp3_to_wav(mp3_filepath):\n",
    "    try:\n",
    "        wav_filepath = mp3_filepath.replace('.mp3', '.wav')\n",
    "        audio = AudioSegment.from_mp3(mp3_filepath)\n",
    "        audio.export(wav_filepath, format='wav')\n",
    "        return wav_filepath\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при конвертации {mp3_filepath} в WAV: {e}\")\n",
    "        return None\n",
    "\n",
    "# Функция загрузки аннотаций\n",
    "def load_annotations(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# Загрузка датасета с аннотациями\n",
    "def load_dataset(data_dir, annotation_files):\n",
    "    dataset = []\n",
    "    for annotation_file in annotation_files:\n",
    "        annotations = load_annotations(os.path.join(ANNOTATION_DIR, annotation_file))\n",
    "        sub_dir = annotation_file.replace('.json', '')\n",
    "        for item in annotations:\n",
    "            if all(k in item for k in ['audio_filepath', 'text', 'label', 'attribute']):\n",
    "                audio_path = os.path.join(data_dir, sub_dir, item['audio_filepath'])\n",
    "                if os.path.exists(audio_path):\n",
    "                    if audio_path.endswith('.mp3'):\n",
    "                        audio_path = convert_mp3_to_wav(audio_path)\n",
    "                    if audio_path:\n",
    "                        dataset.append({\n",
    "                            'audio_filepath': audio_path,\n",
    "                            'text': item['text'],\n",
    "                            'label': item['label'],\n",
    "                            'attribute': item['attribute']\n",
    "                        })\n",
    "    return dataset\n",
    "\n",
    "# Загрузка данных\n",
    "dataset = load_dataset(DATA_DIR, ANNOTATION_FILES)\n",
    "df = pd.DataFrame(dataset)\n",
    "\n",
    "# Функция извлечения MFCC признаков\n",
    "def extract_features(audio_filepath):\n",
    "    try:\n",
    "        signal, sr = librosa.load(audio_filepath, sr=None)\n",
    "        mfccs = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=13)\n",
    "        return np.mean(mfccs.T, axis=0)\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при обработке {audio_filepath}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Извлечение признаков\n",
    "df['features'] = df['audio_filepath'].apply(extract_features)\n",
    "df = df.dropna()  # Удаляем строки с ошибками\n",
    "\n",
    "X = np.array(df['features'].tolist())\n",
    "y = np.array(df['label'])\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Определение модели\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Input(shape=(13,)),  # Входной слой (13 признаков из MFCC)\n",
    "    layers.Dense(64, activation='relu'),  # Первый скрытый слой\n",
    "    layers.Dense(64, activation='relu'),  # Второй скрытый слой\n",
    "    layers.Dense(len(set(y)), activation='softmax')  # Выходной слой (количество классов)\n",
    "])\n",
    "\n",
    "# Компиляция модели\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Обучение модели\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)\n",
    "\n",
    "# Оценка модели на тестовой выборке\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Сохранение модели\n",
    "model.save('train_command_model.h5')\n",
    "\n",
    "# Функция для распознавания речи с использованием Vosk\n",
    "def transcribe_audio(audio_file):\n",
    "    wf = wave.open(audio_file, \"rb\")\n",
    "    rec = KaldiRecognizer(vosk_model, wf.getframerate())\n",
    "\n",
    "    result_text = \"\"\n",
    "    while True:\n",
    "        data = wf.readframes(4000)\n",
    "        if len(data) == 0:\n",
    "            break\n",
    "        if rec.AcceptWaveform(data):\n",
    "            result = json.loads(rec.Result())\n",
    "            result_text += result.get(\"text\", \"\")\n",
    "\n",
    "    final_result = json.loads(rec.FinalResult())\n",
    "    result_text += final_result.get(\"text\", \"\")\n",
    "\n",
    "    return result_text\n",
    "\n",
    "# Классы команд\n",
    "commands = {\n",
    "    0: \"отказ\",\n",
    "    1: \"отмена\",\n",
    "    2: \"подтверждение\",\n",
    "    3: \"начать осаживание\",\n",
    "    4: \"осадить на (количество) вагон\",\n",
    "    5: \"продолжаем осаживание\",\n",
    "    6: \"зарядка тормозной магистрали\",\n",
    "    7: \"вышел из межвагонного пространства\",\n",
    "    8: \"продолжаем роспуск\",\n",
    "    9: \"растянуть автосцепки\",\n",
    "    10: \"протянуть на (количество) вагон\",\n",
    "    11: \"отцепка\",\n",
    "    12: \"назад на башмак\",\n",
    "    13: \"захожу в межвагонное пространство\",\n",
    "    14: \"остановка\",\n",
    "    15: \"вперед на башмак\",\n",
    "    16: \"сжать автосцепки\",\n",
    "    17: \"назад с башмака\",\n",
    "    18: \"тише\",\n",
    "    19: \"вперед с башмака\",\n",
    "    20: \"прекратить зарядку тормозной магистрали\",\n",
    "    21: \"тормозить\",\n",
    "    22: \"отпустить\",\n",
    "}\n",
    "\n",
    "# Функция для классификации команды\n",
    "def classify_command(text):\n",
    "    for command in commands.values():\n",
    "        if command in text:\n",
    "            return command\n",
    "    return \"Unknown Command\"\n",
    "\n",
    "# Функция для оценки команд\n",
    "def evaluate_commands():\n",
    "    annotations = load_annotations(ANNOTATION_VAL_FILE)\n",
    "    correct_predictions = 0\n",
    "    total_predictions = len(annotations)\n",
    "\n",
    "    for item in annotations:\n",
    "        audio_filepath = item['audio_filepath']\n",
    "        label = item['label']\n",
    "\n",
    "        audio_path = os.path.join(VAL_DIR, audio_filepath)\n",
    "        if os.path.exists(audio_path):\n",
    "            transcription = transcribe_audio(audio_path)\n",
    "            prediction = classify_command(transcription)\n",
    "            print(f'Predicted: {prediction}, Actual: {label} for {audio_path}')\n",
    "\n",
    "            if prediction == label:\n",
    "                correct_predictions += 1\n",
    "\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    print(f'\\nTotal Predictions: {total_predictions}, Correct Predictions: {correct_predictions}, Accuracy: {accuracy:.2f}')\n",
    "\n",
    "evaluate_commands()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
