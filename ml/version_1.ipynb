{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Шаг 0: Импорт библиотек\n",
    "Для решения этого задания мы можем использовать библиотеки pandas, librosa для обработки аудио и torch или tensorflow для построения модели."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Константы\n",
    "DATA_DIR = '../data/train/'\n",
    "DATA_DIR_FILES = [\n",
    "    'hr_bot_clear',\n",
    "    'hr_bot_noise',\n",
    "    'hr_bot_synt'\n",
    "]\n",
    "ANNOTATION_DIR = '../data/train/annotation/'\n",
    "ANNOTATION_FILES = [\n",
    "    'hr_bot_clear.json',\n",
    "    'hr_bot_noise.json',\n",
    "    'hr_bot_synt.json'\n",
    "]\n",
    "\n",
    "VAL_DIR = '../data/val/luga/'  # Путь к валидационным данным\n",
    "ANNOTATION_VAL_FILE = os.path.join(VAL_DIR, 'luga.json')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Шаг 1: Подготовка данных\n",
    "Мы начнем с того, что организуем данные, которые мы имеем, и подготовим их к обучению."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Загрузка аннотаций\n",
    "def load_annotations(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# Загрузка данных и их обработка\n",
    "def load_dataset(data_dir, annotation_files):\n",
    "    dataset = []\n",
    "    # Перебираем файлы аннотаций\n",
    "    for annotation_file in annotation_files:\n",
    "        annotations = load_annotations(os.path.join(ANNOTATION_DIR, annotation_file))\n",
    "\n",
    "        # Получаем соответствующую директорию на основе названия файла аннотации\n",
    "        sub_dir = annotation_file.replace('.json', '')\n",
    "        print(f\"Loading from subdirectory: {sub_dir}\")\n",
    "\n",
    "        for item in annotations:\n",
    "            if all(k in item for k in ['audio_filepath', 'text', 'label', 'attribute']):\n",
    "                # Используем os.path.join для правильного формирования пути\n",
    "                audio_path = os.path.join(data_dir, sub_dir, item['audio_filepath'])\n",
    "                print(f\"Checking audio file path: {audio_path}\")\n",
    "\n",
    "                if os.path.exists(audio_path):\n",
    "                    dataset.append({\n",
    "                        'audio_filepath': audio_path,\n",
    "                        'text': item['text'],\n",
    "                        'label': item['label'],\n",
    "                        'attribute': item['attribute']\n",
    "                    })\n",
    "                else:\n",
    "                    print(f\"Audio file does not exist: {audio_path}\")\n",
    "            else:\n",
    "                print(f\"Missing keys in item: {item}\")\n",
    "    return dataset\n",
    "\n",
    "# Загрузка аннотаций и создание DataFrame\n",
    "dataset = load_dataset(DATA_DIR, ANNOTATION_FILES)\n",
    "df = pd.DataFrame(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Шаг 2: Обработка аудио и извлечение признаков\n",
    "Для классификации команд нам нужно извлечь признаки из аудиофайлов. Мы можем использовать MFCC (Mel-Frequency Cepstral Coefficients) как набор признаков."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Извлечение признаков\n",
    "def extract_features(audio_filepath):\n",
    "    try:\n",
    "        # Загрузка аудиофайла\n",
    "        signal, sr = librosa.load(audio_filepath, sr=None)\n",
    "        # Извлечение MFCC\n",
    "        mfccs = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=13)\n",
    "        return np.mean(mfccs.T, axis=0)\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при обработке {audio_filepath}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Извлечение признаков\n",
    "df['features'] = df['audio_filepath'].apply(extract_features)\n",
    "df = df.dropna()  # Удаляем строки с ошибками"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Шаг 3: Подготовка данных для обучения\n",
    "Теперь мы разделим данные на обучающую и тестовую выборки и подготовим их для нейросети."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Подготовка входных данных и меток\n",
    "X = np.array(df['features'].tolist())\n",
    "y = np.array(df['label'])\n",
    "\n",
    "# Разделение на обучающую и валидационную выборки\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Шаг 4: Создание нейронной сети\n",
    "Мы можем использовать библиотеку TensorFlow или PyTorch для создания нейронной сети. Здесь мы создадим простую модель с использованием Keras."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Создание модели\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(13,)),  # Входной слой\n",
    "    layers.Dense(64, activation='relu'),  # Первый скрытый слой\n",
    "    layers.Dense(64, activation='relu'),  # Второй скрытый слой\n",
    "    layers.Dense(23, activation='softmax')  # Выходной слой для 23 классов\n",
    "])\n",
    "\n",
    "# Компиляция модели\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Шаг 5: Обучение модели\n",
    "Теперь мы можем обучить модель на подготовленных данных."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Обучение модели на текстовых данных\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Шаг 6: Тестирование модели на валидационном наборе\n",
    "После обучения мы можем протестировать модель на валидационном наборе."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Оценка модели на валидационном наборе\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Шаг 7: Сохранение модели\n",
    "После завершения обучения мы можем сохранить модель на диск для дальнейшего использования."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Сохранение модели\n",
    "model.save('train_command_model.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Шаг 8: Использование модели\n",
    "Теперь мы можем загрузить модель и использовать её для предсказания на новых аудиофайлах."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Загрузка модели\n",
    "loaded_model = keras.models.load_model('train_command_model.h5')\n",
    "\n",
    "# Функция для предсказания\n",
    "def predict_command(audio_filepath):\n",
    "    features = extract_features(audio_filepath)\n",
    "    if features is not None:\n",
    "        features = np.reshape(features, (1, -1))  # Изменяем размерность\n",
    "        prediction = model.predict(features)\n",
    "        predicted_label = np.argmax(prediction)\n",
    "        return predicted_label\n",
    "    return None\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Основная функция для проверки команд\n",
    "# Основная функция для проверки команд\n",
    "def evaluate_commands():\n",
    "    annotations = load_annotations(ANNOTATION_FILE)\n",
    "\n",
    "    correct_predictions = 0\n",
    "    total_predictions = len(annotations)\n",
    "\n",
    "    # Словарь для хранения статистики\n",
    "    statistics = {\n",
    "        'correct': {},\n",
    "        'total': {},\n",
    "        'accuracy': {}\n",
    "    }\n",
    "\n",
    "    # Обработка каждой аннотации\n",
    "    for item in annotations:\n",
    "        audio_filepath = item['audio_filepath']\n",
    "        label = item['label']\n",
    "\n",
    "        # Формирование полного пути к аудиофайлу\n",
    "        audio_path = os.path.join(VAL_DIR, os.path.dirname(audio_filepath), os.path.basename(audio_filepath))\n",
    "\n",
    "        if os.path.exists(audio_path):\n",
    "            prediction = predict_command(audio_path)  # Получаем предсказание\n",
    "            print(f'Predicted: {prediction}, Actual: {label} for {audio_path}')\n",
    "\n",
    "            # Сохраняем статистику\n",
    "            if label not in statistics['correct']:\n",
    "                statistics['correct'][label] = 0\n",
    "                statistics['total'][label] = 0\n",
    "\n",
    "            statistics['total'][label] += 1\n",
    "\n",
    "            if prediction == label:\n",
    "                correct_predictions += 1\n",
    "                statistics['correct'][label] += 1\n",
    "        else:\n",
    "            print(f'Audio file does not exist: {audio_path}')\n",
    "\n",
    "    # Вычисляем общую точность\n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "\n",
    "    # Сохраняем точность в статистике\n",
    "    statistics['accuracy'] = accuracy\n",
    "\n",
    "    # Выводим статистику\n",
    "    print(f'\\nTotal Predictions: {total_predictions}')\n",
    "    print(f'Correct Predictions: {correct_predictions}')\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print('Detailed statistics per label:')\n",
    "    for label in statistics['total']:\n",
    "        total = statistics['total'][label]\n",
    "        correct = statistics['correct'].get(label, 0)\n",
    "        print(f'Label: {label}, Total: {total}, Correct: {correct}, Accuracy: {correct / total:.2f}' if total > 0 else f'Label: {label}, Total: {total}, Correct: {correct}')\n",
    "\n",
    "# Запуск проверки команд\n",
    "evaluate_commands()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
